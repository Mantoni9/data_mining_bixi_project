{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b28efc-aa18-4710-b56e-c49a2d970955",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03f0aab-5a38-40f1-a9d7-a6c56fc778ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "from datetime import date\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6069b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess(rides_file_path, stations_file_path):\n",
    "    '''\n",
    "    This function is used to read a rides file and all other necessary files and do the preprocessing.\n",
    "    \n",
    "    :param str rides_file_path: path to the rides file\n",
    "    :param str stations_file_path: path to the stations file\n",
    "    :return pd.DataFrame: dataframe ready to be used in the modelling process\n",
    "    '''\n",
    "    \n",
    "    rides_df = pd.read_csv(rides_file_path, parse_dates=[0, 2])\n",
    "    stations_df = pd.read_csv(stations_file_path)\n",
    "    \n",
    "    # turn all column names to lower case\n",
    "    rides_df.columns = rides_df.columns.str.lower()\n",
    "    stations_df.columns = stations_df.columns.str.lower()\n",
    "    \n",
    "    # this happens in file of August 2019, because of invalid station codes\n",
    "    if rides_df['start_station_code'].dtype != 'int':\n",
    "        \n",
    "        # add column for integer values, insert None when a value can not be converted\n",
    "        def to_int_or_none(val):\n",
    "            try:\n",
    "                return(int(val))\n",
    "            except ValueError:\n",
    "                return None\n",
    "\n",
    "        rides_df['start_station_code_int'] = rides_df['start_station_code'].apply(to_int_or_none)\n",
    "        rides_df['end_station_code_int'] = rides_df['end_station_code'].apply(to_int_or_none)\n",
    "\n",
    "        # drop every row where station codes could not be converted to integer\n",
    "        rides_df = rides_df.dropna()\n",
    "        rides_df['start_station_code'] = rides_df['start_station_code_int'].astype('int')\n",
    "        rides_df['end_station_code'] = rides_df['end_station_code_int'].astype('int')\n",
    "        rides_df = rides_df.drop(columns=['start_station_code_int', 'end_station_code_int'])\n",
    "    \n",
    "    # aggregate rides: sum up rides between 0:00 to 12:00 and 12:00 to 0:00\n",
    "    ride_counts_df = rides_df.groupby([pd.Grouper(key='start_date', freq='12h'), 'start_station_code'])['end_date'].count()\n",
    "    ride_counts_df = ride_counts_df.to_frame()\n",
    "    ride_counts_df = ride_counts_df.rename(columns={'end_date': 'count'})\n",
    "    ride_counts_df = ride_counts_df.reset_index()\n",
    "    \n",
    "    # add am/pm flags (am = 0, pm = 1)\n",
    "    ride_counts_df['pm'] = ride_counts_df['start_date'].dt.hour.map({0: 0, 12: 1})\n",
    "    \n",
    "    # join coordinates of stations\n",
    "    ride_counts_df = ride_counts_df.merge(\n",
    "        stations_df[['code', 'latitude', 'longitude']],\n",
    "        left_on='start_station_code',\n",
    "        right_on='code',\n",
    "        # inner join removes any station not specified in the stations dataset\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # add month and weekday\n",
    "    ride_counts_df['month'] = ride_counts_df['start_date'].dt.month\n",
    "    ride_counts_df['weekday'] = ride_counts_df['start_date'].dt.weekday\n",
    "    \n",
    "    # add holyday flag\n",
    "    ca_qc_holidays = holidays.country_holidays('CA', subdiv='QC')\n",
    "    ride_counts_df['holiday'] = ride_counts_df['start_date'].isin(ca_qc_holidays)\n",
    "    \n",
    "    # add weather data\n",
    "    weather_df = pd.read_csv('data/Canadian_climate_history.csv', parse_dates=[0])\n",
    "    weather_df.columns = weather_df.columns.str.lower()\n",
    "    weather_df = weather_df[['local_date', 'mean_temperature_montreal', 'total_precipitation_montreal']]\n",
    "    weather_df = weather_df.rename(\n",
    "        columns={'mean_temperature_montreal': 'mean_temperature',\n",
    "                 'total_precipitation_montreal': 'total_precipitation'}\n",
    "    )\n",
    "    # add date attribute to join on\n",
    "    ride_counts_df['date'] = pd.to_datetime(ride_counts_df['start_date'].dt.date)\n",
    "    ride_counts_df = ride_counts_df.merge(weather_df, left_on='date', right_on='local_date')\n",
    "    \n",
    "    # add distance to city center\n",
    "    def haversine(row):\n",
    "        lon1 = -73.56878\n",
    "        lat1 = 45.50354\n",
    "        lon2 = row['longitude']\n",
    "        lat2 = row['latitude']\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        dlon = lon2 - lon1 \n",
    "        dlat = lat2 - lat1 \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * arcsin(sqrt(a)) \n",
    "        km = 6367 * c\n",
    "        return km\n",
    "\n",
    "    ride_counts_df['distance_to_center'] = ride_counts_df.apply(lambda row: haversine(row), axis=1)\n",
    "    \n",
    "    # add density of stations in nearby area???\n",
    "    \n",
    "    # only keep these columns\n",
    "    ride_counts_df = ride_counts_df[[\n",
    "        'start_date',\n",
    "        'latitude', 'longitude',\n",
    "        'month', 'weekday', 'pm',\n",
    "        'mean_temperature', 'total_precipitation',\n",
    "        'distance_to_center', 'holiday',\n",
    "         # ...\n",
    "        'count'\n",
    "    ]]\n",
    "    \n",
    "    return ride_counts_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d9fd3f-c2ce-4e69-8fef-cfc292fdf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 & 2018 (training data)\n",
    "# try reading file first\n",
    "try:\n",
    "    pd.read_csv('data/preprocessed_data/train.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.DataFrame()\n",
    "    for year in range(2017, 2019):\n",
    "        stations_file_path = f'data/{year}/Stations_{year}.csv'\n",
    "        for month in range(4, 11):\n",
    "            rides_file_path = f'data/{year}/OD_{year}-{month:02d}.csv'\n",
    "            # run preprocessing function and append df\n",
    "            month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "            train_df = pd.concat([train_df, month_df]).reset_index(drop=True)\n",
    "    # save file\n",
    "    train_df.to_csv('data/preprocessed_data/train.csv', index=False)\n",
    "\n",
    "# 2019 (test data)\n",
    "# try reading file first\n",
    "try:\n",
    "    pd.read_csv('data/preprocessed_data/test.csv')\n",
    "except FileNotFoundError:\n",
    "    test_df = pd.DataFrame()\n",
    "    stations_file_path = f'data/{year}/Stations_{year}.csv'\n",
    "    for month in range(4, 11):\n",
    "        rides_file_path = f'data/{year}/OD_{year}-{month:02d}.csv'\n",
    "        # run preprocessing function and append df\n",
    "        month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "        test_df = pd.concat([test_df, month_df]).reset_index(drop=True)\n",
    "    # save file\n",
    "    test_df.to_csv('data/preprocessed_data/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
