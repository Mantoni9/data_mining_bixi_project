{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b28efc-aa18-4710-b56e-c49a2d970955",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03f0aab-5a38-40f1-a9d7-a6c56fc778ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "from datetime import date\n",
    "import holidays\n",
    "import requests\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6069b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess(rides_file_path, stations_file_path):\n",
    "    '''\n",
    "    This function is used to read a rides file and all other necessary files and do the preprocessing.\n",
    "    \n",
    "    :param str rides_file_path: path to the rides file\n",
    "    :param str stations_file_path: path to the stations file\n",
    "    :return pd.DataFrame: dataframe ready to be used in the modelling process\n",
    "    '''\n",
    "    \n",
    "    rides_df = pd.read_csv(rides_file_path, parse_dates=[0, 2])\n",
    "    stations_df = pd.read_csv(stations_file_path)\n",
    "    \n",
    "    # turn all column names to lower case\n",
    "    rides_df.columns = rides_df.columns.str.lower()\n",
    "    stations_df.columns = stations_df.columns.str.lower()\n",
    "    \n",
    "    # this happens in file of 2021\n",
    "    if not 'start_station_code' in rides_df.columns:\n",
    "        rides_df = rides_df.rename(columns={'emplacement_pk_start': 'start_station_code',\n",
    "                                            'emplacement_pk_end': 'end_station_code'})\n",
    "    \n",
    "    # this happens in file of August 2019, because of invalid station codes\n",
    "    if rides_df['start_station_code'].dtype != 'int':\n",
    "        \n",
    "        # add column for integer values, insert None when a value can not be converted\n",
    "        def to_int_or_none(val):\n",
    "            try:\n",
    "                return(int(val))\n",
    "            except ValueError:\n",
    "                return None\n",
    "    \n",
    "        rides_df['start_station_code_int'] = rides_df['start_station_code'].apply(to_int_or_none)\n",
    "        rides_df['end_station_code_int'] = rides_df['end_station_code'].apply(to_int_or_none)\n",
    "    \n",
    "        # drop every row where station codes could not be converted to integer\n",
    "        rides_df = rides_df.dropna()\n",
    "        rides_df['start_station_code'] = rides_df['start_station_code_int'].astype('int')\n",
    "        rides_df['end_station_code'] = rides_df['end_station_code_int'].astype('int')\n",
    "        rides_df = rides_df.drop(columns=['start_station_code_int', 'end_station_code_int'])\n",
    "    \n",
    "    # aggregate rides: sum up rides between 0:00 to 12:00 and 12:00 to 0:00\n",
    "    ride_counts_df = rides_df.groupby([pd.Grouper(key='start_date', freq='12h'), 'start_station_code'])['end_date'].count()\n",
    "    ride_counts_df = ride_counts_df.to_frame()\n",
    "    ride_counts_df = ride_counts_df.rename(columns={'end_date': 'count'})\n",
    "    ride_counts_df = ride_counts_df.reset_index()\n",
    "    \n",
    "    # add am/pm flags (am = 0, pm = 1)\n",
    "    ride_counts_df['pm'] = ride_counts_df['start_date'].dt.hour.map({0: 0, 12: 1})\n",
    "    \n",
    "    # join coordinates of stations\n",
    "    ride_counts_df = ride_counts_df.merge(\n",
    "        stations_df[['code', 'latitude', 'longitude']],\n",
    "        left_on='start_station_code',\n",
    "        right_on='code',\n",
    "        # inner join removes any station not specified in the stations dataset\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # add year, month and weekday\n",
    "    ride_counts_df['year'] = ride_counts_df['start_date'].dt.year\n",
    "    ride_counts_df['month'] = ride_counts_df['start_date'].dt.month\n",
    "    ride_counts_df['weekday'] = ride_counts_df['start_date'].dt.weekday\n",
    "    \n",
    "    # add holyday flag\n",
    "    ca_qc_holidays = holidays.country_holidays('CA', subdiv='QC')\n",
    "    ride_counts_df['holiday'] = ride_counts_df['start_date'].isin(ca_qc_holidays)\n",
    "    \n",
    "    # add weather data\n",
    "    weather_df = pd.read_csv('data/Canadian_climate_history.csv', parse_dates=[0])\n",
    "    weather_df.columns = weather_df.columns.str.lower()\n",
    "    weather_df = weather_df[['local_date', 'mean_temperature_montreal', 'total_precipitation_montreal']]\n",
    "    weather_df = weather_df.rename(\n",
    "        columns={'mean_temperature_montreal': 'mean_temperature',\n",
    "                 'total_precipitation_montreal': 'total_precipitation'}\n",
    "    )\n",
    "    # add date attribute to join on\n",
    "    ride_counts_df['date'] = pd.to_datetime(ride_counts_df['start_date'].dt.date)\n",
    "    ride_counts_df = ride_counts_df.merge(weather_df, left_on='date', right_on='local_date')\n",
    "    \n",
    "    # add distance to city center\n",
    "    def haversine(row):\n",
    "        lon1 = -73.56878\n",
    "        lat1 = 45.50354\n",
    "        lon2 = row['longitude']\n",
    "        lat2 = row['latitude']\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        dlon = lon2 - lon1 \n",
    "        dlat = lat2 - lat1 \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * arcsin(sqrt(a)) \n",
    "        km = 6367 * c\n",
    "        return km\n",
    "\n",
    "    ride_counts_df['distance_to_center'] = ride_counts_df.apply(lambda row: haversine(row), axis=1)\n",
    "    \n",
    "    # add total number of stations in this year\n",
    "    stations_count = len(stations_df['code'].unique())\n",
    "    ride_counts_df['stations_count'] = stations_count\n",
    "    \n",
    "    # add density of stations in nearby area???\n",
    "    \n",
    "    # elevation\n",
    "\n",
    "    # USGS Elevation Point Query Service\n",
    "    url = r'https://nationalmap.gov/epqs/pqs.php?'\n",
    "\n",
    "    def elevation_function(df, lat_column, lon_column):\n",
    "        elevations = []\n",
    "        for lat, lon in zip(df[lat_column], df[lon_column]):\n",
    "\n",
    "            #define rest query params\n",
    "            params = {\n",
    "                'output': 'json',\n",
    "                'x': lon,\n",
    "                'y': lat,\n",
    "                'units': 'Meters'\n",
    "            }\n",
    "\n",
    "             # format query string and return query value\n",
    "            result = requests.get((url + urllib.parse.urlencode(params)))\n",
    "            elevations.append(result.json()['USGS_Elevation_Point_Query_Service']['Elevation_Query']['Elevation'])\n",
    "\n",
    "        df['elevation_meters'] = elevations\n",
    "    \n",
    "    elevation_function(ride_counts_df, 'latitude', 'longitude')\n",
    "    \n",
    "    # only keep these columns\n",
    "    ride_counts_df = ride_counts_df[[\n",
    "        'latitude', 'longitude', 'distance_to_center',\n",
    "        'year', 'month', 'weekday', 'pm', 'holiday',\n",
    "        'mean_temperature', 'total_precipitation',\n",
    "        'stations_count', 'elev_meters_meters', #'density',\n",
    "        'count'\n",
    "    ]]\n",
    "    \n",
    "    return ride_counts_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d9fd3f-c2ce-4e69-8fef-cfc292fdf182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2014 & 2017 (training data)\n",
    "# try reading file first\n",
    "try:\n",
    "    pd.read_csv('data/preprocessed_data/train.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.DataFrame()\n",
    "    for year in range(2014, 2018):\n",
    "        stations_file_path = f'data/{year}/Stations_{year}.csv'\n",
    "        for month in range(4, 11):\n",
    "            rides_file_path = f'data/{year}/OD_{year}-{month:02d}.csv'\n",
    "            # run preprocessing function and append df\n",
    "            month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "            train_df = pd.concat([train_df, month_df]).reset_index(drop=True)\n",
    "    # save file\n",
    "    train_df.to_csv('data/preprocessed_data/train.csv', index=False)\n",
    "\n",
    "# 2018 (model validation data)\n",
    "# try reading file first\n",
    "try:\n",
    "    pd.read_csv('data/preprocessed_data/validation.csv')\n",
    "except FileNotFoundError:\n",
    "    val_df = pd.DataFrame()\n",
    "    stations_file_path = f'data/2018/Stations_2018.csv'\n",
    "    for month in range(4, 11):\n",
    "        rides_file_path = f'data/2018/OD_2018-{month:02d}.csv'\n",
    "        # run preprocessing function and append df\n",
    "        month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "        val_df = pd.concat([val_df, month_df]).reset_index(drop=True)\n",
    "    # save file\n",
    "    val_df.to_csv('data/preprocessed_data/validation.csv', index=False)\n",
    "    \n",
    "# 2019 (test data)\n",
    "try:\n",
    "    pd.read_csv('data/preprocessed_data/test.csv')\n",
    "except FileNotFoundError:\n",
    "    test_df = pd.DataFrame()\n",
    "    stations_file_path = f'data/2019/Stations_2019.csv'\n",
    "    for month in range(4, 11):\n",
    "        rides_file_path = f'data/2019/OD_2019-{month:02d}.csv'\n",
    "        # run preprocessing function and append df\n",
    "        month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "        test_df = pd.concat([test_df, month_df]).reset_index(drop=True)\n",
    "    # save file\n",
    "    test_df.to_csv('data/preprocessed_data/test.csv', index=False)\n",
    "    \n",
    "# 2020 & 2021 (Corona years)\n",
    "#try:\n",
    "#    pd.read_csv('data/preprocessed_data/corona.csv')\n",
    "#except FileNotFoundError:\n",
    "#    corona_df = pd.DataFrame()\n",
    "#    for year in range(2020, 2021):\n",
    "#        stations_file_path = f'data/{year}/Stations_{year}.csv'\n",
    "#        rides_file_path = f'data/{year}/OD_{year}.csv'\n",
    "#        for month in range(4, 11):\n",
    "#            rides_file_path = f'data/{year}/OD_{year}-{month:02d}.csv'\n",
    "#            # run preprocessing function and append df\n",
    "#            month_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "#            corona_df = pd.concat([train_df, month_df]).reset_index(drop=True)\n",
    "#        # run preprocessing function and append df\n",
    "#        year_df = read_and_preprocess(rides_file_path, stations_file_path)\n",
    "#        corona_df = pd.concat(corona_df, year_df).reset_index(drop=True)\n",
    "#    # save file\n",
    "#    corona_df.to_csv('data/preprocessed_data/corona.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b403d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
