{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d13a369-99c5-4ab2-b8ab-b9bc4d58560b",
   "metadata": {},
   "source": [
    "# Model Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a2501-42c3-488b-9f8f-0f7baf8c8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# TODO: modell mit eurem ersetzen\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Empfohlen von sklearn als Alternative zu SVR, da besser skalierbar auf größere Datensätze\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851d13cc-d1db-48f1-aa8e-af9ffa985376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "train_df = pd.read_csv('data/preprocessed_data/train.csv')\n",
    "test_df = pd.read_csv('data/preprocessed_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d09b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop start date for regression (is represented as month, day, pm) \n",
    "train_df = train_df.drop(columns='start_date')\n",
    "test_df = test_df.drop(columns='start_date')\n",
    "\n",
    "# drop null values\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69e98f4-0254-418a-9214-deea6d4bad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "X_train = train_df.drop(columns='count')\n",
    "y_train = train_df['count']\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    test_df.drop(columns='count'),\n",
    "    test_df['count'],\n",
    "    test_size=0.5,\n",
    "    shuffle=True,\n",
    "    random_state=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf1aa43-f423-4156-adf4-6e7b1a93db1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    402899.000000\n",
       "mean         23.192028\n",
       "std          26.375188\n",
       "min           1.000000\n",
       "25%           7.000000\n",
       "50%          15.000000\n",
       "75%          29.000000\n",
       "max         547.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612aa94",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1a4193-d276-4a7a-9c73-1232ec73dd6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "try:\n",
    "    # TODO: file-name ersetzen (in diesem File werden die Ergebnisse des Hyperparameter Tuning gespeichert)\n",
    "    hyperparameters_df = pd.read_csv('data/hyperparameter_tuning/SVR.csv')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    # df containing hyperparameters and evaluation metrics of each run\n",
    "    hyperparameters_df = pd.DataFrame()\n",
    "    \n",
    "    # this function is used by optuna to tune the hyperparameters\n",
    "    def objective(trial):\n",
    "        # TODO: die Hyperparameter mit denen eures Modells ersetzen\n",
    "        # - integers: trial.suggest_int(name, low, high)\n",
    "        # - floats: trial.suggest_int(name, low, high)\n",
    "        # - kategorisch: trial.suggest_categorical(name, choices)\n",
    "        # (https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.trial.Trial.html)\n",
    "        # define hyperparameters\n",
    "        kernel = trial.suggest_categorical('kernel', ['poly', 'rbf'])\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        c_regularizaion = trial.suggest_float('C', 1, 100)\n",
    "        \n",
    "        # TODO: mit eurem Modell ersetzen\n",
    "        # setup and train model\n",
    "        SVR_reg = SVR(\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            C=c_regularizaion\n",
    "        )\n",
    "        SVR_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # make predictions\n",
    "        y_val_pred = SVR_reg.predict(X_val)\n",
    "        \n",
    "        # evaluate predictions\n",
    "        r_squared = r2_score(y_val, y_val_pred)\n",
    "        rmse = mean_squared_error(y_val, y_val_pred) ** 0.5\n",
    "        \n",
    "        # TODO: mit euren Hyperparametern ersetzen\n",
    "        # insert results in dataframe\n",
    "        global hyperparameters_df\n",
    "        hyperparameters_df = hyperparameters_df.append(\n",
    "            {'kernel': kernel,\n",
    "             'gamma': gamma,\n",
    "             'C': c_regularizaion,\n",
    "             'r_squared': r_squared,\n",
    "             'rmse': rmse},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        # return rmse -> optuna will optimize rmse\n",
    "        return rmse\n",
    "        \n",
    "        \n",
    "    study = optuna.create_study()\n",
    "    # start optimization\n",
    "    study.optimize(objective, n_trials=25)\n",
    "    \n",
    "    # TODO: evtl. müsst ihr auch noch mal die Datentypen anpassen\n",
    "    # convert to correct data types\n",
    "    # hyperparameters_df[['n_estimators', 'max_depth']] = hyperparameters_df[['n_estimators', 'max_depth']].astype('int')\n",
    "    \n",
    "    # sort hyperparameter tuning results and save file\n",
    "    hyperparameters_df = hyperparameters_df.sort_values('rmse', ascending=True)\n",
    "    hyperparameters_df = hyperparameters_df.reset_index(drop=True)\n",
    "    hyperparameters_df.to_csv('data/hyperparameter_tuning/SVR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1604c78-99a2-4ada-b6c2-3d46eadb92ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [kernel,  gamma,  C,  r_squared,  rmse]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00be0ae7-5b16-49fd-be21-c212ae88169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # final model evaluation\n",
    "\n",
    "# # TODO: mit eurem Modell und Hyperparametern ersetzen\n",
    "# # build and train model using the most successful hyperparameters\n",
    "# SVR_reg = SVR()\n",
    "# SVR_reg.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions\n",
    "# y_test_pred = SVR_reg.predict(X_test)\n",
    "\n",
    "# # evaluate predictions\n",
    "# r_squared = r2_score(y_test, y_test_pred)\n",
    "# rmse = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "\n",
    "# print(f'R^2:\\t{r_squared}')\n",
    "# print(f'RMSE:\\t{rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528a22b",
   "metadata": {},
   "source": [
    "# LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1622d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-15 18:52:10,852]\u001b[0m A new study created in memory with name: no-name-c2f39912-5bae-4e27-939c-7b41978b5ced\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 18:54:12,799]\u001b[0m Trial 0 finished with value: 41.569516724488714 and parameters: {'epsilon': 0.6000000000000001, 'loss': 'squared_epsilon_insensitive', 'C': 2.548294496818163}. Best is trial 0 with value: 41.569516724488714.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 18:56:09,970]\u001b[0m Trial 1 finished with value: 25.40356959341293 and parameters: {'epsilon': 0.9, 'loss': 'epsilon_insensitive', 'C': 53.50992880565961}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 18:58:11,512]\u001b[0m Trial 2 finished with value: 42.25913250155488 and parameters: {'epsilon': 0.5, 'loss': 'squared_epsilon_insensitive', 'C': 23.684705461449912}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 18:59:56,516]\u001b[0m Trial 3 finished with value: 42.05114853917295 and parameters: {'epsilon': 0.8, 'loss': 'squared_epsilon_insensitive', 'C': 70.22521642744442}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:01:41,581]\u001b[0m Trial 4 finished with value: 42.314139959958766 and parameters: {'epsilon': 0.5, 'loss': 'squared_epsilon_insensitive', 'C': 90.03789613408107}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:03:28,614]\u001b[0m Trial 5 finished with value: 42.72118924464123 and parameters: {'epsilon': 0.0, 'loss': 'squared_epsilon_insensitive', 'C': 54.57799141287337}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:05:16,157]\u001b[0m Trial 6 finished with value: 41.72164011861978 and parameters: {'epsilon': 0.6000000000000001, 'loss': 'squared_epsilon_insensitive', 'C': 3.293084618813647}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:07:03,659]\u001b[0m Trial 7 finished with value: 42.56292731682918 and parameters: {'epsilon': 0.2, 'loss': 'squared_epsilon_insensitive', 'C': 87.8534392996974}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:08:52,477]\u001b[0m Trial 8 finished with value: 37.14047549149332 and parameters: {'epsilon': 0.7000000000000001, 'loss': 'epsilon_insensitive', 'C': 38.497414152504234}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n",
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\NicoDöring\\AppData\\Local\\Temp\\ipykernel_6644\\2731477918.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hyperparameters_df = hyperparameters_df.append(\n",
      "\u001b[32m[I 2022-11-15 19:10:40,882]\u001b[0m Trial 9 finished with value: 42.315746058809836 and parameters: {'epsilon': 0.5, 'loss': 'squared_epsilon_insensitive', 'C': 98.04800753575567}. Best is trial 1 with value: 25.40356959341293.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1    53\n",
      "2    23\n",
      "3    70\n",
      "4    90\n",
      "5    54\n",
      "6     3\n",
      "7    87\n",
      "8    38\n",
      "9    98\n",
      "Name: C, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "try:\n",
    "    # TODO: file-name ersetzen (in diesem File werden die Ergebnisse des Hyperparameter Tuning gespeichert)\n",
    "    hyperparameters_df = pd.read_csv('data/hyperparameter_tuning/LinearSVR.csv')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    # df containing hyperparameters and evaluation metrics of each run\n",
    "    hyperparameters_df = pd.DataFrame()\n",
    "    \n",
    "    # this function is used by optuna to tune the hyperparameters\n",
    "    def objective(trial):\n",
    "        # TODO: die Hyperparameter mit denen eures Modells ersetzen\n",
    "        # - integers: trial.suggest_int(name, low, high)\n",
    "        # - floats: trial.suggest_int(name, low, high)\n",
    "        # - kategorisch: trial.suggest_categorical(name, choices)\n",
    "        # (https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.trial.Trial.html)\n",
    "        # define hyperparameters\n",
    "        epsilon = trial.suggest_float('epsilon', 0, 1, step=0.1)\n",
    "        loss = trial.suggest_categorical('loss', ['epsilon_insensitive', 'squared_epsilon_insensitive'])\n",
    "        c_regularizaion = trial.suggest_float('C', 1, 100)\n",
    "        \n",
    "        # TODO: mit eurem Modell ersetzen\n",
    "        # setup and train model\n",
    "        LinearSVR_reg = LinearSVR(\n",
    "            epsilon=epsilon,\n",
    "            loss=loss,\n",
    "            C=c_regularizaion,\n",
    "            random_state=1\n",
    "        )\n",
    "        LinearSVR_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # make predictions\n",
    "        y_val_pred = LinearSVR_reg.predict(X_val)\n",
    "        \n",
    "        # evaluate predictions\n",
    "        r_squared = r2_score(y_val, y_val_pred)\n",
    "        rmse = mean_squared_error(y_val, y_val_pred) ** 0.5\n",
    "        \n",
    "        # TODO: mit euren Hyperparametern ersetzen\n",
    "        # insert results in dataframe\n",
    "        global hyperparameters_df\n",
    "        hyperparameters_df = hyperparameters_df.append(\n",
    "            { 'epsilon': epsilon,\n",
    "            'loss': loss,\n",
    "             'C': c_regularizaion,\n",
    "             'r_squared': r_squared,\n",
    "             'rmse': rmse},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        # return rmse -> optuna will optimize rmse\n",
    "        return rmse\n",
    "        \n",
    "        \n",
    "    study = optuna.create_study()\n",
    "    # start optimization\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # TODO: evtl. müsst ihr auch noch mal die Datentypen anpassen\n",
    "    # convert to correct data types\n",
    "    hyperparameters_df['epsilon'] = hyperparameters_df['epsilon'].astype('float')\n",
    "    hyperparameters_df['C'] = hyperparameters_df['C'].astype('int')\n",
    "    print(hyperparameters_df['C'])\n",
    "    \n",
    "    # sort hyperparameter tuning results and save file\n",
    "    hyperparameters_df = hyperparameters_df.sort_values('rmse', ascending=True)\n",
    "    hyperparameters_df = hyperparameters_df.reset_index(drop=True)\n",
    "    hyperparameters_df.to_csv('data/hyperparameter_tuning/LinearSVR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607e8ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsilon</th>\n",
       "      <th>loss</th>\n",
       "      <th>C</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>53</td>\n",
       "      <td>0.082401</td>\n",
       "      <td>25.403570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.961364</td>\n",
       "      <td>37.140475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.457046</td>\n",
       "      <td>41.569517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.475062</td>\n",
       "      <td>41.721640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>70</td>\n",
       "      <td>-1.514311</td>\n",
       "      <td>42.051149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epsilon                         loss   C  r_squared       rmse\n",
       "0      0.9          epsilon_insensitive  53   0.082401  25.403570\n",
       "1      0.7          epsilon_insensitive  38  -0.961364  37.140475\n",
       "2      0.6  squared_epsilon_insensitive   2  -1.457046  41.569517\n",
       "3      0.6  squared_epsilon_insensitive   3  -1.475062  41.721640\n",
       "4      0.8  squared_epsilon_insensitive  70  -1.514311  42.051149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac8df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:\t0.02911294246303986\n",
      "RMSE:\t25.88739915504945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\data-mining-bixi\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# final model evaluation\n",
    "\n",
    "# TODO: mit eurem Modell und Hyperparametern ersetzen\n",
    "# build and train model using the most successful hyperparameters\n",
    "LinearSVR_reg = LinearSVR(\n",
    "            epsilon=hyperparameters_df.loc[0, 'epsilon'],\n",
    "            loss=hyperparameters_df.loc[0, 'loss'],\n",
    "            C=hyperparameters_df.loc[0, 'C'],\n",
    "            random_state=1\n",
    ")\n",
    "\n",
    "LinearSVR_reg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_test_pred = LinearSVR_reg.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "r_squared = r2_score(y_test, y_test_pred)\n",
    "rmse = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "\n",
    "print(f'R^2:\\t{r_squared}')\n",
    "print(f'RMSE:\\t{rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('data-mining-bixi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "96e673fa94a25c38f19d506dea23d01ecc2204c15434feb33c96a3bd0d805035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
